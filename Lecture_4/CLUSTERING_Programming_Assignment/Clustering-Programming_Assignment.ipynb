{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35c0eb2a-cf1a-4692-a9aa-206c299530d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "1. Read the Bernoulli Mixture Model Derivation.\n",
    "2. Read about Stochastic Expectation-Maximization (EM) Algorithm: https://www.sciencedirect.com/science/article/pii/S0167947320302504.\n",
    "3. From the given code, modify the EM algorithm to become a Stochastic EM Algorithm.\n",
    "4. Use the data from the paper: https://www.sciencedirect.com/science/article/abs/pii/S0031320322001753\n",
    "5. Perform categorical clustering using the Bernoulli Mixture Model with Stochastic EM Algorithm.\n",
    "6. Compare its performance with K-Modes Algorithm using Folkes-Mallows Index, Adjusted Rand Index, and Normalized Mutual Information Score.\n",
    "7. Compare and contrast the performances, and explain what is happening (i.e. why is FMI always higher than ARI and NMI? Why is ARI and NMI low compared to FMI? etc.)\n",
    "8. Write the report in Latex, push to your github with the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c578398-6c93-4cdc-9312-367e78aca656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import requests\n",
    "from io import StringIO\n",
    "from kmodes.kmodes import KModes\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.metrics import adjusted_rand_score as ARI, normalized_mutual_info_score as NMI, fowlkes_mallows_score as FMI\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ad05d7-0df2-4778-af2c-c00393e412ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d6ef7f7-14d8-4f8e-8b1b-a89cef28f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "419a408f-c704-405d-89f2-062adc5b6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls = {\n",
    "    \"Soybean (Small)\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/soybean/soybean-small.data\",\n",
    "    \"Zoo\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/zoo/zoo.data\",\n",
    "    \"Heart Disease\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\",\n",
    "    \"Breast Cancer Wisconsin (Original)\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\",\n",
    "    \"Dermatology\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/dermatology/dermatology.data\",\n",
    "    \"Letter Recognition (E, F)\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data\",\n",
    "    \"Molecular Biology (Splice-junction Gene Sequences)\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/molecular-biology/splice-junction-gene-sequences/splice.data\",\n",
    "    \"Mushroom\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50c7dac-7020-4e68-b59c-c3d73885cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_dict = {\n",
    "    \"Soybean (Small)\": 4,\n",
    "    \"Zoo\": 7,\n",
    "    \"Heart Disease\": 2,\n",
    "    \"Breast Cancer Wisconsin (Original)\": 2,\n",
    "    \"Dermatology\": 6,\n",
    "    \"Letter Recognition (E, F)\": 2,\n",
    "    \"Molecular Biology (Splice-junction Gene Sequences)\": 3,\n",
    "    \"Mushroom\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45cfeaac-307e-4011-83ae-5a6a23b410a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab3beea-b230-4b8b-9003-8a622dd91799",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1184017f-399f-4893-8c42-9c891d1351c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url in dataset_urls.items():\n",
    "    response = requests.get(url, verify=False)\n",
    "    data = response.text\n",
    "    \n",
    "    data_io = StringIO(data)\n",
    "    df = pd.read_csv(data_io, header=None)\n",
    "    \n",
    "    df = df.replace('?', np.nan) \n",
    "    df = df.dropna()  \n",
    "\n",
    "       if name == \"Letter Recognition (E, F)\":\n",
    "        y = df.iloc[:, 0]\n",
    "        X = df.iloc[:, 1:]\n",
    "    elif name == \"Mushroom\":\n",
    "        y = df.iloc[:, 0]\n",
    "        X = df.iloc[:, 1:]\n",
    "    elif name == \"Molecular Biology (Splice-junction Gene Sequences)\":\n",
    "        y = df.iloc[:, 0].str.strip()\n",
    "        X = pd.DataFrame([list(seq.strip()) for seq in df.iloc[:, 2]])\n",
    "    else:\n",
    "        X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "\n",
    "    \n",
    "    for col in X.columns:\n",
    "        if len(X[col].unique()) <= 1:\n",
    "            X.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    \n",
    "    dataframes[name] = {'features': X, 'targets': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac47f820-7855-4c26-abbb-b18a415093bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_datasets(dataframes):\n",
    "    if 'Zoo' in dataframes:\n",
    "        zoo_df = dataframes['Zoo']['features']\n",
    "        zoo_df = zoo_df.drop(columns=[0])\n",
    "        dataframes['Zoo']['features'] = zoo_df\n",
    "\n",
    "    if 'Heart Disease' in dataframes:\n",
    "        hd_df = dataframes['Heart Disease']['features']\n",
    "        columns_to_drop = [0, 3, 4, 7, 9]\n",
    "        hd_df = hd_df.drop(columns=hd_df.columns[columns_to_drop])\n",
    "        dataframes['Heart Disease']['features'] = hd_df\n",
    "        y_hd = dataframes['Heart Disease']['targets']\n",
    "        dataframes['Heart Disease']['targets'] = y_hd.apply(lambda x: 0 if x == 0 else 1)\n",
    "    \n",
    "    if 'Breast Cancer Wisconsin (Original)' in dataframes:\n",
    "        bcw_df = dataframes['Breast Cancer Wisconsin (Original)']['features']\n",
    "        bcw_df = bcw_df.drop(columns=bcw_df.columns[0])\n",
    "        dataframes['Breast Cancer Wisconsin (Original)']['features'] = bcw_df\n",
    "    \n",
    "    if 'Dermatology' in dataframes:\n",
    "        derm_df = dataframes['Dermatology']['features']\n",
    "        derm_df = derm_df.drop(columns=derm_df.columns[-1])\n",
    "        dataframes['Dermatology']['features'] = derm_df\n",
    "\n",
    "    if 'Letter Recognition (E, F)' in dataframes:\n",
    "        lr_ef_df = dataframes['Letter Recognition (E, F)']['features']\n",
    "        lr_ef_targets = dataframes['Letter Recognition (E, F)']['targets']\n",
    "        mask = lr_ef_targets.isin(['E', 'F'])\n",
    "        dataframes['Letter Recognition (E, F)']['features'] = lr_ef_df[mask]\n",
    "        dataframes['Letter Recognition (E, F)']['targets'] = lr_ef_targets[mask]\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e33f0ed6-1950-4c9f-8872-7055e90233ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = preprocess_datasets(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "571bf326-3c26-4fa3-b671-3a3094f5f9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BernoulliMixture:\n",
    "    def __init__(self, n_components, max_iter, tol=1e-3):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "    def fit(self,x):\n",
    "        self.x = x\n",
    "        self.init_params()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.old_logL = self.get_log_likelihood(log_bernoullis)\n",
    "        for step in range(self.max_iter):\n",
    "            if step > 0:\n",
    "                self.old_logL = self.logL\n",
    "            \n",
    "            self.gamma = self.get_responsibilities(log_bernoullis)\n",
    "            self.remember_params()\n",
    "            self.get_Neff()\n",
    "            self.get_mu()\n",
    "            self.get_pi()\n",
    "            \n",
    "            log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "            self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "            if np.isnan(self.logL):\n",
    "                self.reset_params()\n",
    "                print(self.logL)\n",
    "                break\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.mu = self.old_mu.copy()\n",
    "        self.pi = self.old_pi.copy()\n",
    "        self.gamma = self.old_gamma.copy()\n",
    "        self.get_Neff()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "\n",
    "    def remember_params(self):\n",
    "        self.old_mu = self.mu.copy()\n",
    "        self.old_pi = self.pi.copy()\n",
    "        self.old_gamma = self.gamma.copy()\n",
    "\n",
    "    def init_params(self):\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        self.n_features = self.x.shape[1]\n",
    "        self.pi = 1/self.n_components * np.ones(self.n_components)\n",
    "        self.mu = np.random.RandomState(seed=0).uniform(low=0.25, high=0.75, size=(self.n_components, self.n_features))\n",
    "        self.normalize_mu()\n",
    "\n",
    "    def normalize_mu(self):\n",
    "        sum_over_features = np.sum(self.mu, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            self.mu[k,:] /= sum_over_features[k]\n",
    "\n",
    "    def get_responsibilities(self, log_bernoullis):\n",
    "        gamma = np.zeros(shape=(log_bernoullis.shape[0], self.n_components))\n",
    "        Z =  logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            gamma[:, k] = np.exp(np.log(self.pi[k]) + log_bernoullis[:,k] - Z)\n",
    "        return gamma\n",
    "\n",
    "    def get_log_bernoullis(self, x):\n",
    "        log_bernoullis = self.get_save_single(x, self.mu)\n",
    "        log_bernoullis += self.get_save_single(1-x, 1-self.mu)\n",
    "        return log_bernoullis\n",
    "\n",
    "    def get_save_single(self, x, mu):\n",
    "        x = np.array(x, dtype=np.float64)\n",
    "        mu = np.array(mu, dtype=np.float64)\n",
    "\n",
    "        mu_place = np.where(mu <= 1e-15, 1e-15, mu)\n",
    "        try:\n",
    "            result = np.tensordot(x, np.log(mu_place), axes=(1, 1))\n",
    "        except TypeError as e:\n",
    "            print(\"TypeError encountered:\", e)\n",
    "            print(\"x shape:\", x.shape, \"x dtype:\", x.dtype)\n",
    "            print(\"mu_place shape:\", mu_place.shape, \"mu_place dtype:\", mu_place.dtype)\n",
    "            raise\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_Neff(self):\n",
    "        self.Neff = np.sum(self.gamma, axis=0)\n",
    "\n",
    "    def get_mu(self):\n",
    "        self.mu = np.einsum('ik,id -> kd', self.gamma, self.x) / self.Neff[:,None] \n",
    "\n",
    "    def get_pi(self):\n",
    "        self.pi = self.Neff / self.n_samples\n",
    "\n",
    "    def predict(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        gamma = self.get_responsibilities(log_bernoullis)\n",
    "        return np.argmax(gamma, axis=1)\n",
    "\n",
    "    def get_sample_log_likelihood(self, log_bernoullis):\n",
    "        return logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "\n",
    "    def get_log_likelihood(self, log_bernoullis):\n",
    "        return np.mean(self.get_sample_log_likelihood(log_bernoullis))\n",
    "\n",
    "    def score(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_log_likelihood(log_bernoullis)\n",
    "\n",
    "    def score_samples(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_sample_log_likelihood(log_bernoullis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d75b725-227d-4e33-b50e-e040320fa2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_bernoulli(features, n_components):\n",
    "    bm = BernoulliMixture(n_components=n_components, max_iter=1000, tol=1e-3)\n",
    "    bm.fit(features)\n",
    "    cluster_labels = bm.predict(features)\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d69e0ae5-b830-41b1-9f5b-f3938ad6119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticBernoulliMixture:\n",
    "    def __init__(self, n_components, max_iter, tol=1e-3, n_samples_per_component=10):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.n_samples_per_component = n_samples_per_component  \n",
    "\n",
    "    def fit(self, x):\n",
    "        self.x = x\n",
    "        self.init_params()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.old_logL = self.get_log_likelihood(log_bernoullis)\n",
    "        for step in range(self.max_iter):\n",
    "            if step > 0:\n",
    "                self.old_logL = self.logL\n",
    "            self.stochastic_e_step()\n",
    "            self.remember_params()\n",
    "            self.get_Neff()\n",
    "            self.get_mu()\n",
    "            self.get_pi()\n",
    "            log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "            self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "            if abs(self.logL - self.old_logL) < self.tol:\n",
    "                break\n",
    "            if np.isnan(self.logL):\n",
    "                self.reset_params()\n",
    "                break\n",
    "\n",
    "    def stochastic_e_step(self):\n",
    "        log_probs = np.log(self.pi)[None, :] + self.get_log_bernoullis(self.x)\n",
    "        log_probs -= logsumexp(log_probs, axis=1)[:, None]\n",
    "        probs = np.exp(log_probs)\n",
    "        self.gamma = np.zeros_like(probs)\n",
    "        for i in range(self.x.shape[0]):\n",
    "            for _ in range(self.n_samples_per_component):\n",
    "                sampled_z = np.random.choice(self.n_components, p=probs[i])\n",
    "                self.gamma[i, sampled_z] += 1\n",
    "        self.gamma /= self.n_samples_per_component\n",
    "        \n",
    "    def get_log_bernoullis(self, x):\n",
    "        return np.einsum('ij,kj->ik', x, np.log(self.mu)) + np.einsum('ij,kj->ik', 1-x, np.log(1-self.mu))\n",
    "                \n",
    "    def reset_params(self):\n",
    "        self.mu = self.old_mu.copy()\n",
    "        self.pi = self.old_pi.copy()\n",
    "        self.gamma = self.old_gamma.copy()\n",
    "        self.get_Neff()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "\n",
    "    def remember_params(self):\n",
    "        self.old_mu = self.mu.copy()\n",
    "        self.old_pi = self.pi.copy()\n",
    "        self.old_gamma = self.gamma.copy()\n",
    "\n",
    "    def init_params(self):\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        self.n_features = self.x.shape[1]\n",
    "        self.pi = 1/self.n_components * np.ones(self.n_components)\n",
    "        self.mu = np.random.RandomState(seed=0).uniform(low=0.25, high=0.75, size=(self.n_components, self.n_features))\n",
    "        self.normalize_mu()\n",
    "\n",
    "    def normalize_mu(self):\n",
    "        sum_over_features = np.sum(self.mu, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            self.mu[k,:] /= sum_over_features[k]\n",
    "\n",
    "    def get_responsibilities(self, log_bernoullis):\n",
    "        gamma = np.zeros(shape=(log_bernoullis.shape[0], self.n_components))\n",
    "        Z =  logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            gamma[:, k] = np.exp(np.log(self.pi[k]) + log_bernoullis[:,k] - Z)\n",
    "        return gamma\n",
    "\n",
    "    def get_log_bernoullis(self, x):\n",
    "        log_bernoullis = self.get_save_single(x, self.mu)\n",
    "        log_bernoullis += self.get_save_single(1-x, 1-self.mu)\n",
    "        return log_bernoullis\n",
    "\n",
    "    def get_save_single(self, x, mu):\n",
    "        x = np.array(x, dtype=np.float64)\n",
    "        mu = np.array(mu, dtype=np.float64)\n",
    "\n",
    "        mu_place = np.where(mu <= 1e-15, 1e-15, mu)\n",
    "        try:\n",
    "            result = np.tensordot(x, np.log(mu_place), axes=(1, 1))\n",
    "        except TypeError as e:\n",
    "            print(\"TypeError encountered:\", e)\n",
    "            print(\"x shape:\", x.shape, \"x dtype:\", x.dtype)\n",
    "            print(\"mu_place shape:\", mu_place.shape, \"mu_place dtype:\", mu_place.dtype)\n",
    "            raise\n",
    "\n",
    "        return result\n",
    "\n",
    "    def get_Neff(self):\n",
    "        self.Neff = np.sum(self.gamma, axis=0)\n",
    "\n",
    "    def get_mu(self):\n",
    "        self.mu = np.einsum('ik,id->kd', self.gamma, self.x) / np.sum(self.gamma, axis=0)[:, None]\n",
    "\n",
    "    def get_pi(self):\n",
    "        self.pi = self.Neff / self.n_samples\n",
    "\n",
    "    def predict(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        gamma = self.get_responsibilities(log_bernoullis)\n",
    "        return np.argmax(gamma, axis=1)\n",
    "\n",
    "    def get_sample_log_likelihood(self, log_bernoullis):\n",
    "        return logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "\n",
    "    def get_log_likelihood(self, log_bernoullis):\n",
    "        return np.mean(self.get_sample_log_likelihood(log_bernoullis))\n",
    "\n",
    "    def score(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_log_likelihood(log_bernoullis)\n",
    "\n",
    "    def score_samples(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_sample_log_likelihood(log_bernoullis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e203f449-a149-4ff4-94d6-b532087c2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_stochastic_bernoulli(features, n_components):\n",
    "    sbm = StochasticBernoulliMixture(n_components=n_components, max_iter=1000, tol=1e-3, n_samples_per_component=10)\n",
    "    sbm.fit(features)\n",
    "    cluster_labels = sbm.predict(features)\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acca7393-cf23-4568-9740-8149a376f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmodes(features, n_clusters):\n",
    "    \"\"\"Perform clustering using KModes algorithm.\"\"\"\n",
    "    km = KModes(n_clusters=n_clusters, init='random', n_init=5)\n",
    "    clusters = km.fit_predict(features)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e3b23dd-62b1-4b15-b70a-71a6cb502c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering_algorithms(dataframes, n_clusters_dict, num_runs=10):\n",
    "    results_list = []\n",
    "    for name, data in dataframes.items():\n",
    "        print(\"Processing:\", name)\n",
    "        \n",
    "        features = data['features']\n",
    "        true_labels = data['targets'].squeeze()  \n",
    "        n_clusters = n_clusters_dict.get(name, 2)  \n",
    "        \n",
    "        encoder = OneHotEncoder(sparse=False)\n",
    "        features_encoded = encoder.fit_transform(features)\n",
    "\n",
    "        metrics = {'Bernoulli Mixture': [], 'Stochastic Bernoulli Mixture': [], 'KModes': []}  \n",
    "        \n",
    "        for _ in range(num_runs):\n",
    "             bm_clusters = perform_bernoulli(features_encoded, n_clusters)\n",
    "            ari, nmi, fmi = calculate_metrics(true_labels, bm_clusters)\n",
    "            metrics['Bernoulli Mixture'].append((ari, nmi, fmi))\n",
    "            \n",
    "            sbm_clusters = perform_stochastic_bernoulli(features_encoded, n_clusters)\n",
    "            ari, nmi, fmi = calculate_metrics(true_labels, sbm_clusters)\n",
    "            metrics['Stochastic Bernoulli Mixture'].append((ari, nmi, fmi))\n",
    "            \n",
    "            km_clusters = perform_kmodes(features, n_clusters)\n",
    "            ari, nmi, fmi = calculate_metrics(true_labels, km_clusters)\n",
    "            metrics['KModes'].append((ari, nmi, fmi))\n",
    "\n",
    "        for method, values in metrics.items():\n",
    "            ari_vals, nmi_vals, fmi_vals = zip(*values)\n",
    "            ari_mean, ari_std = np.mean(ari_vals), np.std(ari_vals)\n",
    "            nmi_mean, nmi_std = np.mean(nmi_vals), np.std(nmi_vals)\n",
    "            fmi_mean, fmi_std = np.mean(fmi_vals), np.std(fmi_vals)\n",
    "            results_list.append({\n",
    "                \"Dataset\": name,\n",
    "                \"Method\": method,\n",
    "                \"ARI\": f\"{ari_mean:.4f}±{ari_std:.2f}\",\n",
    "                \"NMI\": f\"{nmi_mean:.4f}±{nmi_std:.2f}\",\n",
    "                \"FMI\": f\"{fmi_mean:.4f}±{fmi_std:.2f}\"\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e02cba4-6145-42f5-8a69-8d581b09bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    return ARI(true_labels, predicted_labels), NMI(true_labels, predicted_labels), FMI(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "002b217e-bdf7-4073-a889-46f738df3495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Soybean (Small)\n",
      "Processing: Zoo\n",
      "Processing: Heart Disease\n",
      "Processing: Breast Cancer Wisconsin (Original)\n",
      "Processing: Dermatology\n",
      "Processing: Letter Recognition (E, F)\n",
      "Processing: Molecular Biology (Splice-junction Gene Sequences)\n",
      "Processing: Mushroom\n"
     ]
    }
   ],
   "source": [
    "results = run_clustering_algorithms(dataframes, n_clusters_dict, num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84d64ca-eb26-4808-95fd-936e1548c377",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Presentation of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4d64b74-174f-4ad6-b77c-0038d1c8d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_results(results_df):\n",
    "    expanded_df = pd.melt(results_df, id_vars=[\"Dataset\", \"Method\"], value_vars=[\"ARI\", \"NMI\", \"FMI\"], var_name=\"Metric\", value_name=\"Value\")\n",
    "    expanded_df[['Metric_Value', 'Std']] = expanded_df['Value'].str.split('±', expand=True)\n",
    "    expanded_df.drop(columns=['Value'], inplace=True) \n",
    "    \n",
    "    expanded_df['Metric_Value'] = expanded_df['Metric_Value'].astype(float)\n",
    "    expanded_df['Std'] = expanded_df['Std'].astype(float)\n",
    "\n",
    "    expanded_df['Metric_Value'] = expanded_df['Metric_Value'].map('{:.4f}'.format) + \"±\" + expanded_df['Std'].map('{:.2f}'.format)\n",
    "    \n",
    "    dataset_order = results_df['Dataset'].unique()\n",
    "    method_order = results_df['Method'].unique()\n",
    "\n",
    "    pivot_df = expanded_df.pivot_table(index=[\"Dataset\", \"Metric\"], columns=\"Method\", values=\"Metric_Value\", aggfunc='first')\n",
    "    \n",
    "    pivot_df = pivot_df.reindex(dataset_order, level='Dataset')\n",
    "    pivot_df = pivot_df.reindex(method_order, axis='columns')\n",
    "\n",
    "    return pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fa7370e-a347-4b4a-be9a-a065833ed6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_results = reformat_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a164506-c0b3-40cd-acf6-f734a06c78b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method                                                    Bernoulli Mixture Stochastic Bernoulli Mixture       KModes\n",
      "Dataset                                            Metric                                                            \n",
      "Soybean (Small)                                    ARI          1.0000±0.00                  0.9815±0.04  0.9237±0.13\n",
      "                                                   FMI          1.0000±0.00                  0.9863±0.03  0.9425±0.10\n",
      "                                                   NMI          1.0000±0.00                  0.9854±0.03  0.9454±0.09\n",
      "Zoo                                                ARI          0.6972±0.00                  0.6685±0.04  0.6890±0.12\n",
      "                                                   FMI          0.7645±0.00                  0.7421±0.04  0.7585±0.09\n",
      "                                                   NMI          0.8028±0.00                  0.7925±0.01  0.7981±0.04\n",
      "Heart Disease                                      ARI          0.3292±0.00                  0.3801±0.01  0.3637±0.02\n",
      "                                                   FMI          0.6646±0.00                  0.6900±0.00  0.6859±0.01\n",
      "                                                   NMI          0.2598±0.00                  0.3019±0.01  0.2834±0.01\n",
      "Breast Cancer Wisconsin (Original)                 ARI          0.8800±0.00                  0.8794±0.00  0.7438±0.05\n",
      "                                                   FMI          0.9445±0.00                  0.9442±0.00  0.8876±0.02\n",
      "                                                   NMI          0.8152±0.00                  0.8146±0.00  0.6397±0.04\n",
      "Dermatology                                        ARI          0.7718±0.00                  0.7372±0.03  0.5625±0.06\n",
      "                                                   FMI          0.8188±0.00                  0.7908±0.03  0.6485±0.05\n",
      "                                                   NMI          0.8291±0.00                  0.7896±0.03  0.6111±0.06\n",
      "Letter Recognition (E, F)                          ARI          0.0021±0.00                  0.0855±0.13  0.2182±0.04\n",
      "                                                   FMI          0.5012±0.00                  0.5571±0.06  0.6182±0.02\n",
      "                                                   NMI          0.0020±0.00                  0.0726±0.12  0.1795±0.04\n",
      "Molecular Biology (Splice-junction Gene Sequences) ARI          0.8589±0.00                  0.8376±0.00  0.0255±0.00\n",
      "                                                   FMI          0.9132±0.00                  0.9001±0.00  0.3766±0.00\n",
      "                                                   NMI          0.7779±0.00                  0.7541±0.00  0.0412±0.01\n",
      "Mushroom                                           ARI          0.5111±0.00                  0.5111±0.00  0.4835±0.01\n",
      "                                                   FMI          0.7915±0.00                  0.7915±0.00  0.7838±0.01\n",
      "                                                   NMI          0.4538±0.00                  0.4538±0.00  0.4464±0.02\n"
     ]
    }
   ],
   "source": [
    "print(formatted_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b0057-85f3-4e74-a88b-fb39211d1aed",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "The results show that the Bernoulli Mixture clustering performs best across the board, followed closely by the Stochastic Bernoulli Mixture. KModes clustering seems to struggle with complex or large datasets.\n",
    "\n",
    "The reason FMI scores tend to be higher than ARI and NMI is because it focuses on the overall number of correct assignments, regardless of how the data is actually grouped. This can make it seem better than it actually is, especially when dealing with messy clusters.\n",
    "\n",
    "ARI and NMI, on the other hand, are stricter judges. They take into account how well the predicted clusters align with the true groupings and penalize both situations where clusters are split too much (over-segmentation) and where they are not distinct enough (under-segmentation). Additionally, ARI considers the possibility of random chance and adjusts the score accordingly, which can lead to lower values overall. NMI looks at the information shared between the clustering and the true labels, and if the clusters don't capture the natural groupings well, the score will suffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bfc292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
